\documentclass{report}
\usepackage{amssymb, amsmath, hyperref}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{endnotes}
\usepackage{color}
\usepackage{bm}
\usepackage{times}
\usepackage{amssymb,latexsym}

\theoremstyle{plain}
\newtheorem{theorem}[subsection]{Theorem}
\newtheorem{proposition}[subsection]{Proposition}
\newtheorem{lemma}[subsection]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}[subsection]{Definition}
\newtheorem{example}[subsection]{Example}
\newtheorem{exercise}[subsection]{Exercise}
\newtheorem{situation}[subsection]{Situation}

\theoremstyle{remark}
\newtheorem{remark}[subsection]{Remark}
\newtheorem{remarks}[subsection]{Remarks}

\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\proj}[1]{\ket{#1}\!\bra{#1}}
\newcommand{\Tr}{\mbox{\rm Tr}}
\newcommand{\Id}{\ensuremath{\mathop{\rm Id}\nolimits}}
\newcommand{\Es}[1]{\textsc{E}_{#1}}

\newcommand{\reg}[1]{{\textsf{#1}}}

\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\K}{\ensuremath{\mathbb{K}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}

\newcommand{\mH}{\mathcal{H}}
\newcommand{\Alg}{\mathcal{A}}

\newcommand{\setft}[1]{\mathrm{#1}}
\newcommand{\Density}{\setft{D}}
\newcommand{\Pos}{\setft{Pos}}
\newcommand{\Proj}{\setft{Proj}}
\newcommand{\Channel}{\setft{C}}
\newcommand{\Unitary}{\setft{U}}
\newcommand{\Herm}{\setft{Herm}}
\newcommand{\Lin}{\setft{L}}
\newcommand{\Trans}{\setft{T}}
\DeclareMathOperator{\poly}{poly}

\newcommand{\eps}{\varepsilon}
\newcommand{\ph}{\ensuremath{\varphi}}

\newcommand{\NP}{\textsc{NP}}

\newcommand{\Acc}{\textsc{Acc}}
\newcommand{\Samp}{\textsc{Samp}}
\newcommand{\Ext}{\ensuremath{\text{Ext}}}

\newcommand{\BD}{\mathbb{QB}}
\newcommand{\DD}{\mathbb{D}}
\newcommand{\DDb}{\mathbb{D'}}
\newcommand{\Pot}{\Phi}

\newcommand{\Hmin}{H_\infty}
\newcommand{\Hmax}{H_{\ensuremath{\text{max}}}}

\numberwithin{equation}{subsection}

\begin{document}
% test 18

\input{blah.tex}

\chapter{Multiplayer games}
\label{chapter:multigames}

\input{blah.tex}


{Hello}\\

A multiplayer game is a single-round interaction between a \emph{referee} and multiple \emph{players}. The game specifies the actions of the referee: with what distribution she selects the questions to the players, and what tuples of answers are valid for each tuple of questions. The players, traditionally referred to as Alice, Bob, Charlie, etc., are always assumed to attempt to maximize their probability of winning (i.e. providing valid answers) in the game. The probability is over both the referee's and the players' randomness. This quantity, the players' maximum winning probability, is usually called the \emph{value} of the game.

Multiplayer games play an important role in theoretical computer science. Their study ca be motivated from at least two vantage points: 
\begin{itemize}
\item \emph{Hardness of approximation for constraint satisfaction problems.} The most famous game in this context is the $3$SAT ``clause-vs-variable'' game. In this game there are two players, Alice and Bob. Both players and the referee are given access to the same $3$SAT formula $\varphi$. Moreover, the players can agree on a strategy after having seen the formula and before the game starts. Once the game starts, the referee selects a clause $C = x \vee y \vee z$ (some of the variables may be negated) uniformly at random, as well as a variable $w\in\{x,y,z\}$ appearing in $C$, again uniformly at random. She sends the triple $\{x,y,z\}$ to Alice, and the single variable $w$ to Bob. Each player is expected to return an assignment to the variables he or she was asked about. The players win if and only if Alice's assignment satisfies the clause $C$, and Bob's assignment is consistent with Alice's on the variable they were asked in common.\\
It is not hard to verify that the maximum success probability in this game is directly related to the largest number of clauses of $\varphi$ that can be simultaneously satisfied by any assignment. Since $3$SAT is $\NP$-hard, it follows that the value of a game specified explicitly (in matrix form, i.e. a table specifying explicitly the distribution on questions and the truth table for valid answer tuples) is NP-hard to compute. \\
In fact, it follows from the PCP theorem that the value is not only hard to compute exactly, but even to approximate within a sufficiently small constant factor. The language of games plays an important role in 
Dinur's proof of the PCP theorem~\cite{dinur2007pcp}, and it has been instrumental in many reductions deriving hardness of approximation for combinatorial problems. It can also be a useful perspective when studying rounding techniques for linear programming (LP) or semidefinite programming (SDP) relaxations of constraint satisfaction problems. 

\item \emph{Interactive protocols in cryptography.} In cryptography, games often play a role as building blocks in \emph{interactive protocols}, where the players are usually referred to as \emph{provers}. A famous game in this context is the two-prover commitment protocol by Ben-Or et al.~\cite{ben1988multi}. This protocol was introduced to show that all languages in NP have two-prover interactive proofs with perfect zero-knowledge. Technically the protocol gives rise to a two-round game: the referee first interacts with the first prover (commit phase), and then with the second prover (reveal phase). Many kinds of games arise in cryptography, with the players sometimes exchanging messages between themselves, some players being trusted (``oracles'') and others not, etc. 
\end{itemize}

Quantum information introduces an exciting twist in the theory of multiplayer games: what if the players are allowed to use entanglement? The game is the same, but the set of allowed strategies has been broadened. While entanglement does not allow the players to communicate,  it could in principle allow them to increase their odds of winning, and indeed this is the case: you already saw this in the example of the CHSH game, and we will see many more examples as we go. 

\begin{remark}
One can ask, why stop at quantum? The most general strategies that respect the no-communication assumption are aptly called \emph{non-signaling strategies}. We will not discuss them in this lecture, but aside from being a nice extension of quantum strategies they have recently become very relevant in designing efficient (single-prover) classical delegation protocols; see e.g.~\cite{kalai2014delegate}.
\end{remark} 

Interestingly, many games have the property that the optimal quantum strategy for the players is essentially unique. This property, called \emph{rigidity}, can be leveraged to devise classical tests that verify that arbitrary quantum devices (the players) perform very specific operations. This opens up a whole new world of possibilities, from the certification of information-theoretic randomness to ``device-independent'' security proofs in cryptography to protocols for delegated computation; we will touch on some of these topics in a subsequent lecture. 

\paragraph{Resources.} A great introduction to complexity-theoretic questions about non-local games is the paper by Cleve et al.~\cite{cleve2004consequences}. The lecture notes by Ji (see module 5 \href{https://uwaterloo.ca/institute-for-quantum-computing/programs/graduate-studies/previous-courses/qic-890891-selected-advanced-topics-quantum-information}{here}) cover CHSH, the Magic Square game, linearity testing (using a slightly different analysis than the one we will give here), and graph-based games. 

\paragraph{Notation.} In this lecture we use the non-standard notation 
$$ \ket{\phi_d} \,=\,\frac{1}{\sqrt{d}} \sum_{i=1}^d \ket{i}\ket{i}$$
for the maximally entangled state in $d$ dimension. In particular, $\ket{\phi_2}$ denotes an EPR pair. 



\chapter{XOR games--edit}
\label{chap:xorgames}

The simplest kind of games to think about are XOR games. An XOR game has the following form:
\begin{enumerate}
  \item The referee selects a pair of questions $(i,j)\in \{1,\ldots, m\}\times \{1,\ldots, n\}$
   according to a distribution $\pi$. 
  \item The referee sends $i$ to Alice and $j$ to Bob. Alice and Bob reply with signs $a_i,b_j\in\{\pm 1\}$ respectively.
  \item The payoff to the players is $a_ib_jc_{ij}$, where $c_{ij}\in\{\pm 1\}$. (Note that the payoff is a number in $\{\pm 1\}$. The interpretation is that, if the payoff is $+1$ the players ``win'', and if it is $-1$ they ``loose''. More general real-valued payoffs may be considered.)
\end{enumerate}
Given questions $i$ and $j$ respectively, the goal of the players is to provide answers whose product equals the target value $c_{ij}$. However, Alice only knows $i$ and Bob only knows $j$, which is what can make the game challenging. The following example introduces the famous CHSH game as an XOR game. 



\subsection{Classical strategies}
\label{section:classicalstrats}

Given an arbitrary XOR game $G$, introduce a matrix $A\in\R^{n\times m}$ with coefficients $G_{ij}=\pi(i,j)c_{ij}$. Then the maximum expected payoff for the players is
 \begin{equation}\label{eq:opt-1}
 \beta(G) \,=\, \max_{a_i,b_j\in\{\pm 1\}}\sum_{i,j} G_{ij}a_ib_j \;.
 \end{equation}
It is not hard to verify that this is related to the value $\omega(G)$ of the game, the maximum propbability for the players to be accepted, as $\omega(G) = \frac{1}{2} + \frac{1}{2}\beta(G)$. 

Conversely, for any $A\in \R^{m\times n}$, we can define $c_{ij}=\text{sign}(A_{ij})$ and $\pi(i,j)=\frac{A_{ij}}{\sum_{k,l}|A_{kl}|}$ to transform any optimization problem of the form~\eqref{eq:opt-1} into an XOR game. You may already know that computing~\eqref{eq:opt-1}, or even approximating it to within a small constant factor, is NP-hard in the worst case; if not, verify that there is a simple reduction from MAXCUT. So approximating the value of a $2$-player XOR game is NP-hard; this is a slightly stronger result than the hardness for ``clause-vs-variable''-type games that we discussed earlier. 

\begin{remark}
In general one may allow the players to use randomized strategies, including both private and shared randomness, to select their answers. It is easy to see that this cannot help in general: if on average (over their random coin tosses) the players achieve a certain payoff, then there must exist some choice of coins that lets them achieve at least the average payoff, and they might as well fix this choice of coins as part of their strategy. 
\end{remark}

\begin{example}\label{ex:chsh}
We let $m=n=2$ and  $c_{11}=c_{12}=c_{21}=1$, $c_{22}=-1$. Thus the players ``win'' if and only if $a_i \oplus b_j = i\wedge j$ (interpreting $i,j\in\{1,2\}$ as Booleans by mapping $1$ to $0$ and $2$ to $1$). This game is called the CHSH game, after its inventors, Clause, Horne, Shimony, and Holt. We can evaluate the maximum expected payoff exactly: 
 $$ \beta(G)=\max_{a_i,b_j\in\{\pm 1\}}\sum_{i,j}\pi(i,j)c_{ij}a_ib_j=\max\frac{1}{4}(a_1b_1+a_1b_2+a_2b_1-a_2b_2)= \frac{1}{2}\;.\footnote{The quantity $\beta(G)$ is called the ``bias'' of the game, which is twice the largest possible advantage over a random strategy.}
  $$
	So the classical value of the game is 
	$$\omega(G) \,=\, \frac{1}{2} + \frac{1}{2}\, \beta(G) \,=\, \frac{3}{4}\;.$$
\end{example}

\subsection{Quantum strategies}
\label{section:quantumstrats}

Now let's consider quantum players allowed to use shared entanglement to help determine their answers. The game is the same, and in particular the verifier, and the question and answer sets, remain classical.  Using that answers in an XOR game are always binary we can represent each player's strategy as a family of observables.

\begin{definition}
A binary observable is a Hermitian matrix $X\in \C^{d\times d}$ such that $X=X^\dagger$ and $X^2=\mathbb{I}$ (in other words, all eigenvalues of $X$ are $\in\{\pm 1\}$). A binary observable $X$ can always be decomposed as $X = X^0 - X^1$ for two projections $X^0$, $X^1$ such that $X^0+X^1 = \Id$, i.e. $\{X^0,X^1\}$ is a projective measurement. 
\end{definition}

 The laws of quantum mechanics state that if Alice and Bob measure their respective half of an entangled state $\ket{\psi} \in \C^d \otimes \C^d$ using observables $X$ and $Y$, then the product of the outcomes they obtain has expectation
\begin{align*}
\Es{}[a\cdot b] &= \Pr\big( (a,b)=(0,0) \big) + \Pr\big( (a,b)=(1,1) \big) - \Pr\big( (a,b)=(0,1) \big)  - \Pr\big( (a,b)=(1,0) \big) \\
&=  \bra{\psi} X^0 \otimes Y^0 \ket{\psi} + \bra{\psi} X^1 \otimes Y^1 \ket{\psi} - \bra{\psi} X^0 \otimes Y^1 \ket{\psi} - \bra{\psi} X^1 \otimes Y^0 \ket{\psi}\\
&=  \bra{\psi} X \otimes Y \ket{\psi} \,\in\,[-1,1]\;.
\end{align*}
You can verify that if we restrict to $d=1$, then the only states are $\ket{\psi} = (e^{i\theta})$ for some real angle $\theta$, the only observables are $X,Y\in\{\pm 1\}$, and the computation above just returns the product of the observables --- this is basically just a classical deterministic strategy. 

With this notation in place we can define the optimal expected payoff for quantum players in an XOR game: 
\begin{equation}\label{eq:def-qval}  
\beta^*(G)=\sup_{\substack{a_i,b_j\in\C^{d\times d}\\ a_i^2=b_j^2=\mathbb{I}\\ a_i=a_i^\dagger\\ b_j=b_j^\dagger}}\,\sum_{i,j}\, A_{ij}\cdot\bra{\psi} a_i\otimes b_j\ket{\psi}\;.
\end{equation}
Note that if we restrict the entanglement to $\ket{\phi_{d}} = d^{-1/2}\sum_{i=1}^d \ket{i}\ket{i}$, a $d$-dimensional maximally entangled state, we obtain a particularly simple formula, since in this case
 $$\bra{\psi} X\otimes Y \ket{\psi} \,=\, \frac{1}{d} \Tr(XY^T)\;.$$
We will slightly abuse notation and write  $\langle X, Y\rangle = \Tr(XY^\dagger)$ to denote the matrix trace inner product. 

\begin{example}\label{ex:chsh}
Consider 
\begin{equation*}
A_0=\left(\begin{array}{cc}1&0\\0&-1\end{array}\right),\qquad
B_0=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}1&1\\1&-1\end{array}\right),\qquad
A_1=\left(\begin{array}{cc}0&1\\1&0\end{array}\right),\qquad
B_1=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}1&-1\\-1&-1\end{array}\right)\;.
\end{equation*}
Then you can verify that $A_0,A_1,B_0,B_1$ are observables; in fact, you can recognize some standard matrices from quantum information. Moreover, 
$$\frac{1}{2} \langle A_0, B_0\rangle = \frac{1}{2}\langle A_0, B_1\rangle = \frac{1}{2} \langle A_1, B_0\rangle =\frac{\sqrt{2}}{2}\;,\quad\text{and}\quad \frac{1}{2}\langle  A_1,B_1\rangle = -\frac{\sqrt{2}}{2}\;.$$
 Plugging these calculations into the definition of the CHSH game (Example~\ref{ex:chsh}), we see that these observables, together with a maximally entangled state in dimension $d=2$, achieve a bias of
$$
\frac{1}{4}\cdot 4\cdot \frac{\sqrt{2}}{2} =\frac{\sqrt{2}}{2} \approx 0.73\;,
$$
which is strictly larger than the bias $1/2$ that we proved optimal for classical players.
\end{example}

The example of the CHSH game shows that quantum players can sometimes strictly outperform their classical peers. This already has a pretty neat (and, arguably, deep) consequence: it is possible to use the CHSH game as a ``statistical test for information-theoretic randomness''! Indeed, any strategy that succeeds in the test  with probability larger than $\frac{1}{2} + \frac{1}{4}$ (a simple condition to verify) cannot be a classical strategy, and in particular it cannot be a deterministic strategy. Thus, any pair of isolated devices (representing the players) that generate an input-output behavior that leads to a sufficiently high success probability in the game is necessarily randomness-generating. Note that this kind of randomness is very different from ``pseudo-randomness'': there is no question of computational power here, and the guarantees provided by the test are information-theoretic!

\subsection{An SDP formulation and Tsirelson's bound}
\label{section:sdp}

Is there any limit to how well quantum players can do in the CHSH game, or more generally in an XOR game? Recall that the optimal expected payoff for quantum players is given by~\eqref{eq:def-qval}:
\begin{equation}\label{eq:qval-2}
\beta^*(G)=\sup_{\substack{A_i,B_j\in\C^{d\times d}\\ A_i^2=B_j^2=\mathbb{I}\\ A_i=A_i^\dagger\\ B_j=B_j^\dagger}}\sum_{i,j} G_{ij}\cdot\bra{\psi} A_i\otimes B_j\ket{\psi} \le \sup_{\substack{\vec{u}_i,\vec{v}_j\in \R^{d^2}\\ \|\vec{u}_i\|=\|\vec{v}_j\|=1}}\sum_{i,j} G_{ij}\vec{u}_i\cdot \vec{v}_j = \text{SDP}(G)\;.
\end{equation}
This inequality holds because we can set $\vec{u}_i=A_i \otimes \Id \ket{\psi}$ and $\vec{v}_j=\Id\otimes B_j \ket{\psi}$. Under such choice, one can verify that
$$
\|\vec{u}_i\|=\|\vec{v}_i\|=1,\qquad 
u_i\cdot v_j=\bra{\psi} A_i \otimes B_j \ket{\psi}\;.
$$
The expression on the right-hand side of~\eqref{eq:qval-2} is nice because it is directly analogous to the expression~\eqref{eq:opt-1} for the classical value: the only difference is that we now optimize over inner products of unit vectors in any dimension, instead of just products of $\pm 1$ values. Although we will not show explicitly why, those of you familiar with semidefinite program will easily recognize that $\text{SDP}(AG)$ is, indeed, an SDP. In particular, the quantity can be approximated to within $\pm\eps$ in time polynomial in $n$, $m$, and $\log(1/\eps)$. 

Note that~\eqref{eq:qval-2} is only an upper bound. How good is it? Let's first use it to prove \emph{Tsirelson's theorem}, which states that the lower bound of $\frac{\sqrt{2}}{2}$ on the quantum bias of the CHSH game obtained earlier is tight. 

\begin{theorem}[Tsirelson]\label{thm:tsirelson}
For $G$ the CHSH game, it holds that $\beta^*(G) \leq \frac{\sqrt{2}}{2}$.
\end{theorem}

\begin{proof}
For the CHSH game we can write
\begin{align*}
\text{SDP}(G) &= \sup_{\substack{\vec{u}_i,\vec{v}_j\in \R^{d^2}\\ \|\vec{u}_i\|=\|\vec{v}_j\|=1}} \frac{1}{4} \big(\vec{u}_0 \cdot \vec{v}_0 + \vec{u}_1 \cdot \vec{v}_0 + \vec{u}_0 \cdot \vec{v}_1 - \vec{u}_1 \cdot \vec{v}_1\big)\\
 &= \sup_{\substack{\vec{u}_i,\vec{v}_j\in \R^{d^2}\\ \|\vec{u}_i\|=\|\vec{v}_j\|=1}} \frac{1}{4} \big(\vec{u}_0 \cdot (\vec{v}_0 + \vec{v}_1) +  \vec{u}_1 \cdot (\vec{v}_0 -\vec{v}_1)\big)\\
 & = \sup_{\substack{\vec{v}_j\in \R^{d^2}\\ \|\vec{v}_j\|=1}} \frac{1}{4} \big(\|\vec{v}_0 + \vec{v}_1\| + \|\vec{v}_0 -\vec{v}_1\| \big)\\
 & \leq \sup_{\substack{\vec{v}_j\in \R^{d^2}\\ \|\vec{v}_j\|=1}} \frac{\sqrt{2}}{4} \big( \|\vec{v}_0 + \vec{v}_1\|^2 + \|\vec{v}_0 -\vec{v}_1\|^2\big)^{1/2} \\
&= 2\frac{\sqrt{2}}{4} \;.
\end{align*}
Here for the third line we used that for any nonzero $\vec{v}$ the supremum over unit $\vec{u}$ of $\vec{u}\cdot \vec{v}$ is $\|\vec{v}\|$, achieved at $\vec{u} = \vec{v}/\|\vec{v}\|$; the fourth line is the Cauchy-Schwarz inequality; the last expands the squares and uses that $\vec{v}_0$ and $\vec{v}_1$ are unit vectors. 
\end{proof}

Tsirelson's proof of his theorem was a bit different: he worked directly with the operators, and considered the square of the game value. We will revisit his proof a little later. 

Theorem~\ref{thm:tsirelson} shows that the bound~\eqref{eq:qval-2} is tight for the CHSH game. What is amazing is that it is \emph{always} tight, for any XOR game! This is another result by Tsirelson. 

\begin{exercise}\label{ex:tsirelson}
Show that given a vector solution to SDP($G$) it is always possible to find a quantum strategy that achieves exactly the same value. \emph{[Hint: Consider Hermitian matrices $C_1,\ldots,C_d \in \C^{D\times D}$ that square to identity and pairwise anti-commute. For any vector $u$, consider $u\mapsto C(u) = \sum_i u_i C_i$. What can you say about $C(u)$? And about $\bra{\phi_{D}} C(u) \otimes C(v)\ket{\phi_D}$? ]}
\end{exercise}

The fact that~\eqref{eq:qval-2} is an equality has amazing consequences for the study of XOR games. In particular, it implies that: 
\begin{itemize}
  \item The right-hand size of~\eqref{eq:qval-2} can be expressed as a semidefinite program, hence the maximum expected payoff of quantum players can be computed efficiently (recall that for classical players it is NP-hard);\footnote{This fact holds for XOR games. However, in general it can be a very hard problem to determine the maximum success probability of quantum players in a two-payer game: Slofstra~\cite{slofstra2017set} recently showed that the problem is undecidable.}
  \item The proof of Tsirelson's theorem in Exercise~\ref{ex:tsirelson} is explicit, hence an optimal quantum strategy can always be found efficiently;
  \item Grothendieck's inequality from functional analysis shows that the ratio of $\text{SDP}(G)/\beta^*(G)$ is always at most a universal constant, Grothendieck's constant $K_G \leq 1.782\ldots$: this implies that, in XOR games, quantum players can only ever achieve a payoff that is a constant factor larger than the optimal classical payoff.
\end{itemize}

\begin{remark}
There are many interesting games that are not XOR games. A good example is the \emph{Magic Square game}. This game is a ``pseudo-telepathy'' game, which means that the quantum value is $1$ (there is a perfect quantum strategy), while the classical value is strictly below $1$. It is known that XOR games cannot be pseudo-telepathy games. 
\end{remark}

\chapter{Rigidity for quantum games}
\label{chapter:rigidity}

Let's look back at the proof of Theorem~\ref{thm:tsirelson}. It has an interesting ``rigidity'' property. If we try to make all inequalities tight, then we don't have much choice. First of all, for the third line we need to have $\vec{u}_0 = \frac{\vec{v}_0+\vec{v}_1}{\|\vec{v}_0+\vec{v}_1\|}$ and $\vec{u}_1 = \frac{\vec{v}_0-\vec{v}_1}{\|\vec{v}_0-v\vec{v}_1\|}$. So the only freedom is in choosing $\vec{v}_0$ and $v\vec{v}_1$. But then to have equality in the application of the Cauchy-Schwarz inequality in the fourth line we need $\|\vec{v}_0+\vec{v}_1\|=\|\vec{v}_0-\vec{v}_1\|$ which, using that $\vec{v}_0$ and $\vec{v}_1$ are both unit vectors, requires $\vec{v}_0 \cdot \vec{v}_1 = 0$. Conversely, you can check that any two unit vectors $\vec{v}_0$ and $\vec{v}_1$ that are orthogonal will achieve the optimum (provided $\vec{u}_0,\vec{u}_1$ are defined from $\vec{v}_0,\vec{v}_1$ as indicated above). So the only freedom we have left is which orthonormal pair to choose for $\vec{v}_0,\vec{v}_1$. However, note that any two orthonormal pairs are related by an orthogonal transformation, and the value of SDP($G$) is invariant under any orthogonal rotation of the $v_j$, provided the $\vec{u}_i$ are rotated in the inverse direction. So this last degree of freedom is unavoidable, and we have completely characterized the set of optimal vector solutions. 

\begin{exercise}
Suppose $\vec{u}_0,\vec{u}_1,\vec{v}_0,\vec{v}_1$ are unit vectors that achieve a value of $\frac{\sqrt{2}}{2}-\eps$, for some small $\eps>0$, in SDP($G$) for $G$ the CHSH game. Is the pair $(\vec{v}_0,\vec{v}_1)$ necessarily close to an orthonormal pair? If so, how would you measure distance to an orthonormal pair?  
\end{exercise}

The above argument formulates ``rigidity'' of the CHSH game at the level of vectors. Our goal in this section is to develop the tools for making similar statements directly at the level of the quantum strategy, i.e. the players' observables and shared quantum state. A result of our investigations will be a theorem stating that the quantum strategy for the CHSH game introduced in Example~\ref{ex:chsh} is  unique up to local rotations. But we'll go much further than the CHSH game, and develop techniques that can be used to show rigidity statements for large classes of games. 


\subsection{Approximate group representations}
\label{section:approx-group}

We first make a little detour through the theory of group representations. For $d$-dimensional matrices  $A,B$ and $\sigma$ such that $\sigma$ is positive semidefinite, write 
$$\langle A,B\rangle_\sigma = \mathrm{Tr}(AB^* \sigma)\;,$$
where we use $B^*$ to denote the conjugate-transpose. This is an extension of our earlier notation for the matrix inner product, which is recovered for $\sigma = \Id$. If $\sigma$ is the totally mixed state, then we obtain a dimension-normalized variant of the trace inner product. We will also write $\|A\|_\sigma = \langle A,A\rangle_\sigma^{1/2}$. 

Given an arbitrary finite group $G$ (not necessarily abelian), a group representation of $G$ is a map $f:G \to U_d(\C)$, the group of $d\times d$ unitary matrices, such that $f$ is a homomorphism: for any $x,y\in G$, $f(x^{-1}y)=f(x)^* f(y)$, where we used $^*$ to denote the conjugate transpose (which, for unitary matrices, corresponds to taking the inverse). The following definition introduces a notion of \emph{approximate} group representation.  

\begin{definition}\label{def:approx-rep}
Given a finite group $G$, an integer $d\geq 1$, $\eps\geq 0$, and a $d$-dimensional positive semidefinite matrix $\sigma$ with trace $1$, an $(\eps,\sigma)$-representation of $G$ is a function $f: G \to U_d(\C)$, the unitary group of $d\times d$ matrices, such that 
\begin{equation}\label{eq:gh-condition}
\Es{x,y\in G} \,\Re\big(\big\langle f(x)^*f(y) ,f(x^{-1}y) \big\rangle_\sigma\big) \,\geq\, 1-\eps\;,
\end{equation} 
where the expectation is taken under the uniform distribution over $G$.
\end{definition}

\begin{remark}
The condition \eqref{eq:gh-condition} in the definition is very closely related to Gowers' $U^2$ norm
$$\|f\|_{U^2}^4 \,=\, \Es{xy^{-1}=zw^{-1}}\, \big\langle f(x)f(y)^* ,f(z)f(w)^* \big\rangle_\sigma.$$
While a large Gowers norm implies closeness to an affine function, we are interested in testing homomorphisms, and the condition \eqref{eq:gh-condition} will arise naturally from our calculations in the next section. 
\end{remark}

\subsection{The Gowers-Hatami theorem}
\label{section:ghtheorem}

There are many possible notions for approximate group representation. The most often considered one replaces the norm in Definition~\ref{def:approx-rep} by the operator norm. An inconvenient of that variant is that in general approximate representations are not always close to exact representations (see, for example, the famous problem on ``approximately commuting'' versus ``nearly commuting'' operators). In contrast, 
Gowers and Hatami~\cite{gowers2015inverse} showed that in the case of Definition~\ref{def:approx-rep}, approximate group representations can always be ``rounded'' to a nearby exact representations. We state and prove a slightly more general, but quantitatively weaker, variant of their result.

\begin{theorem}[Gowers-Hatami]\label{thm:gh}
Let $G$ be a finite group, $\eps\geq 0$, and $f:G\to U_d(\C)$ an $(\eps,\sigma)$-representation of $G$. Then there exists a $d'\geq d$, an isometry $V:\C^d\to \C^{d'}$, and a representation $g:G\to U_{d'}(\C)$ such that 
$$\Es{x\in G}\, \big\| f(x) - V^*g(x)V \big\|_\sigma^2\, \leq\, 2\,\eps.$$ 
\end{theorem}

Gowers and Hatami limit themselves to the case of $\sigma = d^{-1}I_d$, which corresponds to the dimension-normalized Frobenius norm. In this scenario they in addition obtain a tight control of the dimension $d'$, and show that one can always take $d'\ = (1+O(\eps))d$ in the theorem. We will see a much shorter proof than theirs (the proof is implicit in their argument) that does not seem to allow to recover this estimate. 

Note that  Theorem \ref{thm:gh} does not in general hold  with $d'=d$. The reason is that it is possible for $G$ to have an approximate representation in some dimension $d$, but no exact representation of the same dimension: to obtain an example of this, take any group $G$ that has all non-trivial irreducible representations of large enough dimension, and create an approximate representation in e.g. dimension one less by ``cutting off'' one row and column from an exact representation. The dimension normalization induced by the norm $\|\cdot\|_\sigma$ will barely notice this, but it will be impossible to ``round'' the approximate representation obtained to an exact one without modifying the dimension. 

\begin{exercise}
Prove Theorem~\ref{thm:gh} for the case where $G$ is the single-qubit Weyl-Heisenberg group, which is the $8$-element matrix group generated by the Pauli $\sigma_X$ and $\sigma_Z$ matrices. \emph{[Hint: Consider $V:\C^d \to \C^{d'} \otimes \C^2$, where $\C^{d'} \simeq \C^d \otimes \C^2 $, defined by 
$$V\ket{\varphi} = \frac{1}{2}\big((\Id\otimes \Id + A_0 \otimes \sigma_X + A_1 \otimes \sigma_Z + A_0A_1 \otimes \sigma_X\sigma_Z)\otimes \Id \big)(\ket{\varphi} \otimes \ket{\phi_2}\;,$$
where $\ket{\varphi}$ is an arbitrary state in $\C^d$, $\ket{\phi_2}$ is an EPR pair on the last two copies of $\C^2$, and $A_0=f(\sigma_X)$, $A_1=f(\sigma_Z)$ act on $\C^d$. 
 ]}
\end{exercise}

The main ingredient for the proof is an appropriate notion of Fourier transform over non-abelian groups. Given an irreducible representation $\rho: G \to U_{d_\rho}(\C)$, define 
\begin{equation}\label{eq:fourier}
 \hat{f}(\rho) \,=\, \Es{x\in G} \,f(x) \otimes \overline{\rho(x)}.
\end{equation}
In case $G$ is abelian, we always have $d_\rho=1$, the tensor product is a product, and \eqref{eq:fourier} reduces to the usual definition of Fourier coefficient. The only properties we will need of irreducible representations is that they satisfy the relation
\begin{equation}\label{eq:ortho}
\sum_\rho \,d_\rho\,\mathrm{Tr}(\rho(x)) \,=\, |G|\delta_{xe}\;,
\end{equation}
for any $x\in G$. Note that plugging in $x=e$ (the identity element in $G$) yields $\sum_\rho d_\rho^2= |G|$. 

\begin{proof}[Proof of Theorem \ref{thm:gh}]
Our first step is to define an isometry $V:\C^d \to \C^d \otimes (\oplus_\rho \C^{d_\rho} \otimes \C^{d_\rho})$ by
$$ V :\;u \in \C^d \,\mapsto\, \bigoplus_\rho \,d_\rho^{1/2} \sum_{i=1}^{d_\rho} \,\big(\hat{f}(\rho) (u\otimes e_i)\big) \otimes e_i,$$
where the direct sum ranges over all irreducible representations $\rho$ of $G$ and $\{e_i\}$ is the canonical basis. 
Note what $V$ does: it ``embeds'' any vector $u\in \C^d$ into a direct sum, over irreducible representations $\rho$, of a $d$-dimensional vector of $d_\rho\times d_\rho$ matrices. Each (matrix) entry of this vector can be thought of as the Fourier coefficient of the corresponding entry of the vector $f(x)u$ associated with $\rho$. 
The fact that $V$ is an isometry follows from the appropriate extension of Parseval's formula:  
\begin{eqnarray*}
& V^* V &= \sum_\rho d_\rho \sum_i (I\otimes e_i^*) \hat{f}(\rho)^*\hat{f}(\rho) (I\otimes e_i)\\
&&= \Es{x,y}\,  f(x)^*f(y) \sum_\rho d_\rho \sum_i  (e_i^* \rho(x)^T \overline{\rho(y)} e_i)\\
&&= \sum_\rho \frac{d_\rho^2}{|G|}I = I,
\end{eqnarray*}
where for the second line we used the definition \eqref{eq:fourier} of $\hat{f}(\rho)$ and  for the third we used \eqref{eq:ortho} and the fact that $f$ takes values in the unitary group.

Next define
$$g(x) = \bigoplus_\rho \,\big(I_d \otimes I_{d_\rho} \otimes \rho(x)\big), $$
a direct sum over all irreducible representations of $G$ (hence itself a representation). Lets' first compute the ``pull-back'' of $g$ by $V$: following a similar calculation as above, for any $x\in G$, 
\begin{eqnarray*}
& V^*g(x) V  &=  \sum_{\rho}  d_\rho \sum_{i,j} (I\otimes e_i^*)\hat{f}(\rho)^* \hat{f}(\rho)(I\otimes e_j) \otimes e_i^* \rho(x) e_j ) \\
&& =  \Es{z,y}\,  f(z)^*f(y)  \sum_{\rho}  d_\rho \sum_{i,j} (e_i^* \rho(z)^T \overline{\rho(y)} e_j) \big( e_i^* \rho(x) e_j \big) \\
&& =  \Es{z,y}\,  f(z)^*f(y)  \sum_{\rho}  d_\rho \mathrm{Tr}\big( \rho(z)^T \overline{\rho(y)}  {\rho(x)^T} \big) \\
&& =  \Es{z,y}\,  f(z)^*f(y)  \sum_{\rho}  d_\rho \mathrm{Tr}\big( \rho(z^{-1}y x^{-1}) \big) \\
&& =  \Es{z}\,  f(z)^*f(zx) , 
\end{eqnarray*}
where the last equality uses \eqref{eq:ortho}.
It then follows that 
\begin{eqnarray*}
&\Es{x}\, \big\langle f(x), V^*g(x) V \big\rangle_\sigma &=  \Es{x,z} \mathrm{Tr}\big( f(x) f(zx)^* f(z)\sigma\big).
\end{eqnarray*}  
This relates correlation of $f$ with $V^*gV$ to the quality of $f$ as an approximate representation and proves the theorem. 
\end{proof}

\subsection{Rigidity for the CHSH game}
\label{section:chsh}

Now let's see what this all has to do with the CHSH game. We will use the theory of approximate group representations to prove the following theorem, originally due to~\cite{summers1988maximal} (with slightly weaker bounds; see also~\cite{mckague2012robust} for the $O(\sqrt{\eps})$ dependence).

\begin{theorem}\label{thm:rigid-chsh}
Let $\eps>0$, and suppose that a strategy for the players  in the CHSH game, using  a bipartite state $\ket{\psi}\in\C^d\otimes \C^d$ and observables $A_0,A_1$ for Alice and $B_0,B_1$ for Bob, achieves a bias at least $\sqrt{2}/2-\eps$ in the game. Then there are local isometries $V_A,V_B:\C^d \to \C^2 \otimes \C^{d'}$ such that 
\begin{equation}\label{eq:chsh-state}
\big\| V_A \otimes V_B \ket{\psi} - \frac{1}{\sqrt{2}}\big(\ket{00}+\ket{11}\big) \otimes \ket{\psi'} \big\|^2 = O(\sqrt{\eps}) \;,
\end{equation}
and 
\begin{equation}\label{eq:chsh-alice}
\big\|( V_A \otimes V_B)( A_0 \otimes \Id )\ket{\psi} - (\sigma_X \otimes \Id)\frac{1}{\sqrt{2}}(\ket{00}+\ket{11}) \otimes \ket{\psi'} \big\| \,=\, O\big(\sqrt{\eps}\big)\;,
\end{equation}
and a similar relation holds with $A_0$ replaced by $A_1$ and $\sigma_X$ replaced by $\sigma_Z$. Moreover, analogous relations hold for Bob's observables. 
\end{theorem}

It is important to note what the theorem says, and what it does not say. It does not say that the state $\ket{\psi}$ shared by the players must be close to an EPR pair --- it says that, \emph{up to local rotations}, the state must be close to an EPR pair \emph{tensored with an ancilla state}. Since local unitaries have no effect on the Schmidt coefficients, it does imply that the original state shared by the players have Schmidt coefficients that can be split into two roughly even batches --- and in particular, that there are at least two of them. 

 The theorem also does not say anything about the observables $A_0$, $A_1$ themselves. Eq.~\eqref{eq:chsh-alice} only talks about the action of the observable \emph{on the state}. This is inevitable, as the game only ``observes'' this action. In particular, it is perfectly possible for $A_0$ to look like something completely arbitrary in a portion of space in which the reduced density of $\ket{\psi}$ on Alice's space is zero, or very small. But the theorem does say that, in terms of ``observable consequences'' only, the action of $A_0$ on $\ket{\psi}$ is comparable to the action of $\sigma_X$ on one half of an EPR pair. Although this may sound relatively weak, we will see that it can be exploited all the way into a complete ``leash'' for an arbitrary computation. 



\begin{proof}
For the first step of the proof we follow Tsirelson's argument showing a bound of $\frac{\sqrt{2}}{2}$ on the quantum value of the CHSH game. Tsirelson's idea was to consider the square
\begin{align}
(A_0\otimes B_0 + A_0\otimes B_1 + A_1\otimes B_0 - A_1\otimes B_1 )^2 &=( (A_0+A_1)\otimes B_0 + (A_0-A_1)\otimes B_1 )^2\label{eq:bellop}\\
&= 4\Id\otimes \Id + (A_1A_0-A_0A_1)\otimes (B_0B_1-B_1B_0)\;.\notag
\end{align}
This last term has operator norm at most $8$, and as a result the CHSH operator $A_0\otimes B_0 + A_0\otimes B_1 + A_1\otimes B_0 - A_1\otimes B_1$ has operator norm at most $\sqrt{8}$; Tsirelson's bound on the quantum value of CHSH follows by dividing by $4$ and observing that the players' choice of entangled state cannot beat the largest eigenvector.

Furthermore, under the assumption that the strategy achieves a bias of at least $\sqrt{2}/2-\eps$ in the game, using $|\bra{\psi}X\ket{\psi}|^2 \leq \bra{\psi}XX^*\ket{\psi}$ for any Hermitian $X$, the left-hand side of~\eqref{eq:bellop}, when evaluated on $\ket{\psi}$, must be at least $8(1-\eps)^2$. Applying the Cauchy-Schwarz inequality it follows that both conditions
$$\Tr((A_1A_0 + A_0A_1)^2\rho_A) = O({\eps})\qquad \text{and}\qquad \Tr((B_0B_1+B_1B_1)^2 \rho_B) = O({\eps})$$
must hold, where $\rho_A$ and $\rho_B$ are the reduced density matrices of $\ket{\psi}$ on Alice and Bob respectively. 
Using the notation introduced in Section~\ref{sec:approx-group}, this says that 
\begin{equation}\label{eq:a-ac}
\|A_0A_1 + A_1A_0\|_{\rho_A}^2 = O({\eps})\;,
\end{equation}
 i.e. $A_0$ and $A_1$ approximately commute. 

Now here comes the key observation. Consider the $8$-element group $H$ generated by the Pauli matrices $\sigma_X$ and $\sigma_Z$, i.e. 
$$H\,=\,\pm\big\{ \Id,\, \sigma_X,\,\sigma_Z,\, \sigma_X\sigma_Z\big\}\;.$$
Then I claim that $A_0$ and $A_1$ induce an approximate representation of $H$, by setting 
$$ f(\pm \Id)=\pm\Id,\quad f(\pm\sigma_X)=\pm A_0,\quad\quad f(\pm\sigma_Z)=\pm A_1,\quad f(\pm\sigma_X\sigma_Z) = \pm A_0A_1\;.$$
Note that this is a legal definition, since $A_0$, $A_1$, and $A_0A_1$ are all unitary. Moreover, using only~\eqref{eq:a-ac} and the fact that $A_0$ and $A_1$ are observables, it is immediate to verify that the conditions of Theorem~\ref{thm:gh} are satisfied, i.e. $f$ is an $(O({\eps}),\rho_A)$-representation of $H$. 

Applying the theorem, there must exist an exact representation of $H$ to which $f$ is close. However, the representation theory of $H$ is not complicated. It has four $1$-dimensional representations, but all of them map $-\Id$ to $1$, so they cannot be close to $f$. Hence we are left with the unique irreducible $2$-dimensional representation of $H$, which is precisely given by the Pauli matrices!

We're almost done. We can apply the  same considerations to Bob's operators $B_0$ and $B_1$, except that here we will choose to rotate the representation so that it sends $\sigma_X$ to the Hadamard matrix $H$ and $\sigma_Z$ to the matrix $G$. This is another valid representation; it is the same as the standard one, but rotated. 

Finally we need to verify the condition on $\ket{\psi}$. Note that by assumption 
$$ \frac{1}{4}\bra{\psi} A_0 \otimes B_0 + A_0 \otimes B_1 + A_1 \otimes B_0 - A_1\otimes B_1 \ket{\psi} \geq \frac{\sqrt{2}}{2} - \eps\;,$$
which then implies 
$$ \frac{1}{4} \bra{\psi}(V_A\otimes V_B)^\dagger \big( (\sigma_X \otimes H + \sigma_X \otimes G + \sigma_Z \otimes H - \sigma_Z\otimes G)\otimes\Id\big) (V_A\otimes V_B)\ket{\psi} \geq \frac{\sqrt{2}}{2} - O({\eps})\;,$$
i.e. 
\begin{equation}\label{eq:xz-v}
\frac{1}{2}\bra{\psi}(V_A\otimes V_B)^\dagger \big( (\sigma_X \otimes \sigma_X + \sigma_Z \otimes \sigma_Z )\otimes \Id\big)(V_A\otimes V_B)\ket{\psi} \geq 1 - O({\eps})\;.
\end{equation}
Now observe that $\frac{1}{2}(\sigma_X \otimes \sigma_X + \sigma_Z \otimes \sigma_Z )$ is an observable with a single eigenvalue $1$, with associated eigenvector $\ket{\phi_2}$, and all other eigenvalues equal to $0$ or $-1$. Therefore,~\eqref{eq:xz-v} implies 
\[ \big\|\big(\bra{\phi_2}\otimes \Id\big)(V_A\otimes V_B)|\psi\rangle\big\|^2 \,\geq\, 1-O({\eps})\;,\]
which means that $(V_A\otimes V_B)|\psi\rangle = \ket{\phi_2} \otimes \ket{\psi'} + \ket{\psi''}$ for some sub-normalized states $\ket{\psi'}$ and $\ket{\psi''}$ such that $\|\ket{\psi''}\|^2 = O(\eps)$. This proves the theorem. 
\end{proof}

\end{document}
